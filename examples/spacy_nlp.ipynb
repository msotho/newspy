{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-03T18:30:21.059522Z",
     "start_time": "2023-09-03T18:30:13.534276Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U newspy polars spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download textcat_multilabel\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from newspy.models import Source\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Entity:\n",
    "    name: str\n",
    "    label: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Article:\n",
    "    title: str\n",
    "    url: str\n",
    "    abstract: str\n",
    "    published: str\n",
    "    source: Source\n",
    "    entities: list[Entity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import polars as pl\n",
    "\n",
    "from newspy import client as newspy\n",
    "from newspy.models import Language\n",
    "\n",
    "newsorg_api_key = \"NEWSAPI_API_KEY\"\n",
    "newspy.configure(newsorg_api_key=newsorg_api_key)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "articles = newspy.get_articles(language=Language.EN)\n",
    "## articles = rss.get_articles()\n",
    "\n",
    "articles_nlp = []\n",
    "for article in articles:\n",
    "    if article.abstract is None:\n",
    "        print(f\"Skipping url: {article.url} title: {article.title} because it has no abstract\")\n",
    "        continue\n",
    "\n",
    "    text = \". \".join([article.title, article.abstract])\n",
    "\n",
    "    entities = [Entity(name=ent.text, label=ent.label_) for ent in nlp(text, disable=['tok2vec', 'tagger', 'parser',\n",
    "                                                                                      'senter', 'attribute_ruler',\n",
    "                                                                                      'lemmatizer']).ents]\n",
    "    articles_nlp.append(\n",
    "        Article(\n",
    "            source=article.source,\n",
    "            url=article.url,\n",
    "            title=article.title,\n",
    "            abstract=article.abstract,\n",
    "            published=article.published,\n",
    "            entities=entities\n",
    "        )\n",
    "    )\n",
    "\n",
    "articles_nlp_df = pl.DataFrame(articles_nlp)\n",
    "\n",
    "articles_nlp_df.write_csv(\"scratchpad/articles_nlp.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d13a76cf3045afc5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
